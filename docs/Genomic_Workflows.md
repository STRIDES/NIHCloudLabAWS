### Creating the Genomics Core Environment
When running genomics workflows using AWS Batch you need three pieces. The first is a private virtual private cloud (VPC). This has been configured for you so you can skip the creation of this step. The second piece you need is the Genomics Workflow Core Environment and the third is a Workflow Orchestration environment which will be either Cromwell or Nextflow. 

Begin with the creation of the core environment using the Stack Formation template launched from [here](https://docs.opendata.aws/genomics-workflows/core-env/introduction.html). Click `Launch Stack` and then leave the first page as defaults and click `Next`. Name your stack name, and then name the bucket where you want genomic core files to go. In theory you can have Stack Formation create a bucket for you, but we recommend creating an empty S3 bucket ahead of time, listing that bucket in the cell that says `S3 Bucket Name`, and then for `Existing Bucket` say `Yes`. For `VPC ID`, click the only option, and for `VPC Subnet IDs` select both private subnets. `Number of Subnets` = 2. You can leave the rest of this page as default, although you may want to increase `Default Min vCPU` to have more CPUs always running in your Batch cluster. Click `Next`, click `Next` again, and then on the review page, review your selections and agree to the terms at the bottom. When you click `Create Stack` at the bottom, it is going to create core infrastructure, including an EC2 Auto Scaling Group that will handle job submissions from Cromwell or Nextflow. 

### Cromwell on AWS Batch
If you want to submit jobs to a Cromwell server on AWS, you can follow the instructions on the [Genomics Workflows Page](https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-overview.html), but with a few tweaks that we identified in our testing. First off, you need to make sure that you first create the [Genomics Workflow Core Infrastructure](https://docs.opendata.aws/genomics-workflows/core-env/introduction.html). Then, on the Cromwell page, you can skip the VPC (virtual private cloud) creation because your account already has a default VPC. 

Click `Launch Stack` for `Cromwell Resource`, then leave the first page as defaults and click `Next`. On the next page, create a unique stack name, like cromwell-resources-DATE. `Namespace` can. be the same as `Stack name` or else the project name. For `GWFCoreNamespace`, put in the name of your Genomics Workflow Core environment. For `VPC ID` you can select the only option, then for `Server Subnet ID` pick either of the two options. For `Database Subnet IDs` select the two subnets. The rest can be left as default, or modified as desired, then click `Next`. The following page can be left as default, then click `Next`. On the review page, review all your selections, then click `Launch Stack`. 

The stack will take about 10 minutes to finish, you can monitor progress under `CloudFormation > Stacks`. If you select the Stack name, then `Events`, you can monitor the stack being created. If you have an error, this is the best place to figure out where things went wrong. 

Once the stack is launched, you can submit jobs to the server a few different ways. The first is using the Swagger UI, but to access this you can't use a public DNS address like the documentation suggests because cloud lab does not allow external IP addresses. Thus, you need to use the internal IP, which you can find on the info page of the Cromwell Server EC2 instance. Find the Prive IP Address, and paste this into your Browser. This address may be blocked on Chrome, so if that is the case for you, try a different browser. 

You can also submit jobs from the command line from with the Cromwell EC2 instance. While viewing the instance in EC2, click `Connect`, then click `Session Manager` and then `Connect`. Now you can use something like the example command in the AWS docs. 

### Nextflow on AWS Batch
